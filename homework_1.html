<div id="warm-up" class="slide section level1">
<h1>Warm Up</h1>
<ul>
<li><span class="math inline"><em>F</em> = <em>m</em> ⋅ <em>a</em></span></li>
<li><span class="math inline"><em>E</em> = <em>m</em> ⋅ <em>c</em><sup>2</sup></span></li>
<li><span class="math inline">𝒪(<em>n</em> ⋅ <em>l</em><em>o</em><em>g</em>(<em>n</em>))</span></li>
</ul>
</div>
<div id="section" class="slide section level1">
<h1></h1>
<ol style="list-style-type: decimal">
<li>Supervised</li>
<li>Unsupervised</li>
<li>Reinforcement</li>
</ol>
</div>
<div id="section-1" class="slide section level1">
<h1></h1>
<p>1x5</p>
</div>
<div id="representation-of-x" class="slide section level1">
<h1>Representation of <span class="math inline"><em>x</em></span></h1>
<ul>
<li><span class="math inline"><em>x</em></span> is usually not a simple (vector of) number(s). How to tell it to a computer?</li>
<li>Example: bananas vs. apples</li>
<li><strong>Feature engineering</strong>: manually craft functions to <strong>extract</strong> features from raw data, e.g,. SIFT, bag-of-words.</li>
<li>Automated feature extraction in deep learing: E.g., filters in CNNs.</li>
<li>If <span class="math inline"><em>x</em></span> involves categorical values (e.g., gender), there are usually two approaches: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"><strong>One-hot encoding</strong></a> and <a href=""><strong>embedding</strong></a> (in DL context, to be discussed later).</li>
</ul>
</div>
<div id="supervised-ml" class="slide section level1">
<h1>Supervised ML</h1>
<ul>
<li>Given many pairs of inputs and outputs: <span class="math inline">{(<strong>X</strong><sub><strong>1</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>1</strong></sub>), (<strong>X</strong><sub><strong>2</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>2</strong></sub>), …, (<strong>X</strong><sub><strong>N</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>N</strong></sub>)}</span>,</li>
<li>that underline a “black-box” function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> ↦ ℝ<sup><em>m</em></sup></span> such that <span class="math inline">∀<em>i</em> ∈ [1..<em>n</em>], <em>f</em>(<strong>X</strong><sub><em>i</em></sub>) = <strong>y</strong><sub><em>i</em></sub></span>,</li>
<li>construct a function <span class="math inline"><em>f̂</em></span> that approximates the function <span class="math inline"><em>f</em></span>.</li>
<li>“approximate”: usually <span class="math inline">min ||<em>f̂</em>(<em>x</em>) − <em>f</em>(<em>x</em>)||<sup><em>p</em></sup></span> where <span class="math inline"><em>p</em></span> is usually 1 or 2. <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">See <span class="math inline">ℓ<sub><em>p</em></sub></span>-norm</a> . <!-- - In other words, $f$ is a black box. And we need to find $\hat{f}$ that mimick the black box.  --></li>
<li>The process of finding the approximation function <span class="math inline"><em>f̂</em></span> is called <strong>training</strong> or <strong>learning</strong>.</li>
<li><span class="math inline"><em>f̂</em></span> is called a <strong>model</strong> or an <strong>estimator</strong>.</li>
<li><span class="math inline"><strong>X</strong><sub><strong>i</strong></sub></span>: an <strong>input</strong> (especially when raw data is used as the input) or <strong>feature vector</strong> (if using feature engineering).</li>
<li><span class="math inline"><strong>y</strong><sub><strong>i</strong></sub></span>, often <span class="math inline"> ∈ ℝ<sup>1</sup></span> a <strong>label</strong> (in classification) or <strong>target</strong> (used more generally and lately).</li>
<li>Classification vs. Regression: When <span class="math inline"><em>y</em></span> is continuous or discrete. In modern DL context, such division is usually no mentioned, expecially in generative tasks.</li>
</ul>
</div>
